{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize various metrics\n",
    "\n",
    "This notebook provides an example of looking at different metrics to identify effects of different events (e.g. stay at home orders, outlier deaths, etc.)\n",
    "\n",
    "Make sure to run batch model fitting to generate `data/metro_areas.csv` before running this notebook.\n",
    "\n",
    "```\n",
    "python fit_models.py --specfile=metro_areas\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from scipy import ndimage, optimize, signal\n",
    "import statsmodels.api as sm\n",
    "import os\n",
    "import pickle\n",
    "import requests\n",
    "from scipy.interpolate import make_interp_spline, BSpline\n",
    "from time import mktime\n",
    "from scipy import ndimage\n",
    "\n",
    "from modeling import dataproc, sir_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sir_model(r, i, total_model_days, df, metric, sampling_rate, name):\n",
    "    \"\"\"Plot the model death rates and total deaths vs actual data.\n",
    "    \n",
    "    Args:\n",
    "        r: Array holding daily recovered population values from SIR model\n",
    "        i: Array holding daily infected population values from SIR model\n",
    "        total_model_days: Total number of modeled days to plot\n",
    "        df: Dataframe holding metric values.\n",
    "        metric: The type of metric to plot ('Cases' or 'Deaths')\n",
    "        sampling_rate: Number of samples per day used to simulate the model.\n",
    "        name: A name to attach to the plot.\n",
    "    \"\"\"\n",
    "    plot_start_time = df['Date'].min().timestamp()\n",
    "    plot_step_size = 24 * 60 * 60 / sampling_rate\n",
    "    plot_end_time = plot_start_time + total_model_days * 24 * 60 * 60 \n",
    "    plot_timestamps = np.arange(plot_start_time, plot_end_time, plot_step_size)\n",
    "    plot_dates = [datetime.utcfromtimestamp(x) for x in plot_timestamps]\n",
    "    print('peak date', plot_dates[np.argmax(i)])\n",
    "    # Plot peak infection\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    ax.ticklabel_format(useOffset=False)\n",
    "    ax.ticklabel_format(style='plain')\n",
    "    ax.plot(plot_dates[:-sampling_rate],\n",
    "            (r[sampling_rate:] - r[:-sampling_rate]),\n",
    "            c='g',\n",
    "            label='model ' + metric + ' rate',\n",
    "            linewidth=4)\n",
    "    ax.plot(df['Date'].to_list()[:-1],\n",
    "            (df[metric] - df[metric].shift())[1:], label='actual ' + metric + ' rate', c='r', linewidth=4)\n",
    "    ax.set_title('SIR model for ' + name)\n",
    "    ax.set_xlabel('Number of days')\n",
    "    ax.set_ylabel('Number of individuals')\n",
    "    plt.legend()\n",
    "    plt.plot()\n",
    "    \n",
    "    # Plot recovery\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    ax.ticklabel_format(useOffset=False)\n",
    "    ax.ticklabel_format(style='plain')\n",
    "    ax.plot(plot_dates, r, c='g',\n",
    "            label='model ' + metric, linewidth=4)\n",
    "    ax.plot(df['Date'].to_list(), df[metric], label='actual ' + metric, c='r', linewidth=4)\n",
    "    ax.set_title('SIR model for ' + name)\n",
    "    ax.set_xlabel('Number of days')\n",
    "    ax.set_ylabel('Number of individuals')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Covid-19 and Census Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datastore = dataproc.DataStore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model params dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_df = pd.read_csv('data/states.csv', index_col='Unnamed: 0', parse_dates=['Date'])\n",
    "model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the best points to ignore? Use a median filter and threshold\n",
    "sample_df = model_df[model_df['Area'] == 'Los Angeles']['Frac Infected']\n",
    "sample_np = sample_df.to_numpy()\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(sample_np, label='raw', linewidth=4)\n",
    "plt.plot(ndimage.maximum_filter(sample_np, 5)[2:], label='max filter')\n",
    "plt.plot(signal.medfilt(sample_np, 5), label='median filter')\n",
    "plt.plot(ndimage.gaussian_filter1d(sample_np, 2), label='gaussian kernel')\n",
    "plt.legend()\n",
    "\n",
    "logistic_coef = np.polyfit(np.arange(len(sample_np)), np.log(sample_np / (1 - sample_np)), deg=1)\n",
    "\n",
    "logistic_fit = 1 / (1 + np.exp(-logistic_coef[1] * np.arange(len(sample_np)) - logistic_coef[0]))\n",
    "plt.plot(logistic_fit)\n",
    "# Gaussian kernel probably looks best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE_OFFSET = -20\n",
    "plt.figure(figsize=(15, 8))\n",
    "for area_name in model_df['Area'].unique():\n",
    "    # Remove outliers\n",
    "    area_df = model_df[(model_df['Area'] == area_name) & (model_df['Date'] >= '2020-04-15')]\n",
    "    min_frac, max_frac = area_df.quantile(0.1)['Frac Infected'], area_df.quantile(0.9)['Frac Infected']\n",
    "    max_mse = area_df.quantile(0.9)['MSE']\n",
    "    print(area_name, min_frac, max_frac)\n",
    "    filtered_df = area_df[(area_df['Frac Infected'] >= min_frac) & \n",
    "                          (area_df['Frac Infected'] <= max_frac) &\n",
    "                          (area_df['MSE'] <= max_mse)]\n",
    "\n",
    "    r_np = filtered_df[['Date', 'R']].to_numpy()\n",
    "\n",
    "    ts = [mktime((x + timedelta(DATE_OFFSET)).timetuple()) for x in r_np[:,0]]\n",
    "    min_ts = ts[0]\n",
    "    max_ts = ts[-1]\n",
    "    # Gaussian kernel smoothing\n",
    "    y_fit = ndimage.gaussian_filter1d(np.log(r_np[:,1].astype(float)), 1)\n",
    "\n",
    "    xnew = np.linspace(min_ts, max_ts, 100)\n",
    "\n",
    "    spl = make_interp_spline(ts, y_fit, k=2)  # type: BSpline\n",
    "    power_smooth = spl(xnew)\n",
    "    xnew = [datetime.utcfromtimestamp(x) for x in xnew]\n",
    "    #plt.scatter(r_np[:,0] + timedelta(DATE_OFFSET), r_np[:,1], label=area_name + ' raw R')\n",
    "    plt.plot(xnew, np.exp(power_smooth), linewidth=4, label=area_name + ' smoothed R')\n",
    "plt.plot(r_np[:,0] + timedelta(DATE_OFFSET), [1.0] * r_np.shape[0],\n",
    "            linewidth=4, linestyle=':', c='k', label='R = 1')\n",
    "plt.title('R values')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = area_df[(area_df['Frac Infected'] >= min_frac) & \n",
    "                      (area_df['Frac Infected'] <= max_frac) &\n",
    "                      (area_df['MSE'] <= max_mse)]\n",
    "\n",
    "for area_name in model_df['Area'].unique():\n",
    "\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    area_df = model_df[(model_df['Area'] == area_name) & (model_df['Date'] >= '2020-04-15')]\n",
    "    min_frac, max_frac = area_df.quantile(0.05)['Frac Infected'], area_df.quantile(0.95)['Frac Infected']\n",
    "    max_mse = area_df.quantile(0.9)['MSE']\n",
    "    filtered_df = area_df[(area_df['Frac Infected'] >= min_frac) & \n",
    "                          (area_df['Frac Infected'] <= max_frac) &\n",
    "                          (area_df['MSE'] <= max_mse)]\n",
    "    r_np = filtered_df[['Date', 'R']].to_numpy()\n",
    "    r_np_unfiltered = area_df[['Date', 'R']].to_numpy()\n",
    "#     plt.scatter(r_np_unfiltered[:,0] + timedelta(DATE_OFFSET), r_np_unfiltered[:,1], linewidth=4, label=area_name + ' R raw')\n",
    "#     plt.scatter(r_np_unfiltered[:,0] + timedelta(DATE_OFFSET), [1.0] * r_np_unfiltered.shape[0], linewidth=4, linestyle=':', label='R = 1')\n",
    "\n",
    "    # 300 represents number of points to make between T.min and T.max\n",
    "    ts = [mktime((x + timedelta(DATE_OFFSET)).timetuple()) for x in r_np[:,0]]\n",
    "    min_ts = ts[0]\n",
    "    max_ts = ts[-1]\n",
    "\n",
    "    y_fit = ndimage.gaussian_filter1d(np.log(r_np[:,1].astype(float)), 1)\n",
    "\n",
    "    xnew = np.linspace(min_ts, max_ts, 100)\n",
    "\n",
    "    spl = make_interp_spline(ts, y_fit, k=2)  # type: BSpline\n",
    "    power_smooth = spl(xnew)\n",
    "    xnew = [datetime.utcfromtimestamp(x) for x in xnew]\n",
    "    plt.plot(xnew, np.exp(power_smooth), linewidth=4, label=area_name + ' R filtered')\n",
    "    # plt.plot(r_np[:,0] + timedelta(DATE_OFFSET), r_np[:,1], linewidth=4, label=area_name + ' filtered')\n",
    "    plt.title('R values')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DATE_OFFSET = -17\n",
    "area_names = model_df['Area'].unique()\n",
    "plt.figure(figsize=(15, 8))\n",
    "for area_name in area_names:\n",
    "    r_np = model_df[model_df['Area'] == area_name][['Date', 'R']].to_numpy()\n",
    "    plt.plot(r_np[:,0] + timedelta(DATE_OFFSET), r_np[:,1], linewidth=4, label=area_name)\n",
    "plt.plot(r_np[:,0] + timedelta(DATE_OFFSET), [1.0] * r_np.shape[0], linewidth=4, linestyle=':')\n",
    "plt.title('R values')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df[model_df['Area'] == 'New Orleans'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sheltering in place effect on infection rate\n",
    "\n",
    "How many people does an infected person infect per day? Models trained with new data may reveal a sudden change in this parameter based on sheltering-in-place orders. For example, New York, Michigan, and Louisiana all implement sheltering-in-place orders around 3/22-3/24, and the \"infection rate\" based on deaths suddenly dropped about a week later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "shelter_dates_7_days = {'NYC': '2020-03-29',\n",
    "                        'Detroit': '2020-03-31'\n",
    "                       }\n",
    "\n",
    "for area in ['NYC', 'Detroit', 'New Orleans']:\n",
    "    model_area_df = model_df[model_df['Area'] == area]\n",
    "    plt.plot(model_area_df['Date'], model_area_df['Infection Rate'], linewidth=5, label=area)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly detection\n",
    "\n",
    "Can we use the model MSE to detect anomalies in the death rate?\n",
    "\n",
    "Notice that there seems to be a recent sudden shift in prediction error around 4/15 for New Orleans, 4/16 for Detroit and New York! Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for area in ['NYC', 'Detroit', 'New Orleans']:\n",
    "    model_area_df = model_df[(model_df['Area'] == area) & (model_df['Date'] <= '2020-04-18')]\n",
    "    plt.plot(model_area_df['Date'], model_area_df['MSE'], linewidth=5, label=area)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check data for one such area and date range\n",
    "model_df[(model_df['Area'] == 'New Orleans') & (model_df['Date'] >= '2020-04-12') & (model_df['Date'] <= '2020-04-18')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom plots\n",
    "\n",
    "What is the fraction of countries with Coronavirus cases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "countries = [\n",
    "    ('Italy', 'Italy'),\n",
    "    ('Spain', 'Spain'),\n",
    "    ('United Kingdom', 'United Kingdom'),\n",
    "    ('US', 'US'),\n",
    "    ('Germany', 'Germany'),\n",
    "    ('Brazil', 'Brazil'),\n",
    "    ('India', 'India'),\n",
    "    ('Canada', 'Canada')\n",
    "]\n",
    "METRIC = 'Deaths'\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "for AREA_OF_INTEREST in countries:\n",
    "    if len(AREA_OF_INTEREST) <= 2:\n",
    "        area_df, population = datastore.get_time_series_for_area(AREA_OF_INTEREST[0])\n",
    "    else:\n",
    "        area_df, population = datastore.get_time_series_for_area(\n",
    "            AREA_OF_INTEREST[0], AREA_OF_INTEREST[2], AREA_OF_INTEREST[3])\n",
    "\n",
    "    plt.plot(area_df['Date'], area_df[METRIC] / population * 100, label=AREA_OF_INTEREST[0], linewidth=4)\n",
    "plt.title('% ' + METRIC + ' / Population')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('% of population')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "for AREA_OF_INTEREST in countries:\n",
    "    if len(AREA_OF_INTEREST) <= 2:\n",
    "        area_df, population = datastore.get_time_series_for_area(AREA_OF_INTEREST[0])\n",
    "    else:\n",
    "        area_df, population = datastore.get_time_series_for_area(\n",
    "            AREA_OF_INTEREST[0], AREA_OF_INTEREST[2], AREA_OF_INTEREST[3])\n",
    "\n",
    "    plt.plot(area_df['Date'], area_df['Deaths'] / area_df['Cases'] * 100, label=AREA_OF_INTEREST[0], linewidth=4)\n",
    "plt.title('Case fatality rate')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('% deaths / cases')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day of week reporting trends\n",
    "\n",
    "The [US reporting trend](https://www.worldometers.info/coronavirus/country/us/) seems to indicate that Sundays have the lowest number of reported deaths, followed by Mondays. Both of these values are pretty significant. What can we do to denoise these measurements?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum up past 4 weeks\n",
    "DAYS_OF_THE_WEEK = ['Mon', 'Tues', 'Wed', 'Thurs', 'Fri', 'Sat', 'Sun']\n",
    "\n",
    "AREA_OF_INTEREST = ('US', 'New York', 36, [])\n",
    "if len(AREA_OF_INTEREST) <= 2:\n",
    "    area_df, population = datastore.get_time_series_for_area(AREA_OF_INTEREST[0])\n",
    "else:\n",
    "    area_df, population = datastore.get_time_series_for_area(\n",
    "        AREA_OF_INTEREST[0], AREA_OF_INTEREST[2], AREA_OF_INTEREST[3])\n",
    "    \n",
    "area_df['dow'] = area_df['Date'].dt.dayofweek  # 0 is Monday, 6 is Sunday\n",
    "#area_df['Cases'] = area_df['Cases'] - area_df['Cases'].shift(1)\n",
    "area_df['Deaths'] = area_df['Deaths'] - area_df['Deaths'].shift(1)\n",
    "area_df['Deaths Squared'] = area_df['Deaths'] * area_df['Deaths']\n",
    "\n",
    "dow_sum = None\n",
    "weeks = 5\n",
    "\n",
    "weekly_sum = 0\n",
    "weekly_sum_squared = 0\n",
    "for days_before in range(weeks*7-1, weeks*7+6): #7 days shift\n",
    "    for week in range(weeks):\n",
    "        start_date = area_df['Date'].max() + timedelta(-days_before+week*7)\n",
    "        norm_dow = area_df[\n",
    "            (area_df['Date'] >= start_date) &\n",
    "            (area_df['Date'] <= start_date + timedelta(6))\n",
    "        ].groupby('dow').sum()\n",
    "        dow_mean = norm_dow['Deaths'].mean()\n",
    "        norm_dow['Deaths'] /= dow_mean\n",
    "        norm_dow['Deaths Squared'] /= (dow_mean ** 2)\n",
    "        weekly_sum += norm_dow['Deaths'].sum()\n",
    "        weekly_sum_squared += norm_dow['Deaths Squared'].sum()\n",
    "        if dow_sum is None: # 1 week of data\n",
    "            dow_sum = norm_dow\n",
    "        else:\n",
    "            dow_sum += norm_dow\n",
    "# Total number of samples is weeks * 7, so we take the mean by dividing by weeks * 7\n",
    "death_mean = dow_sum['Deaths'] / weeks / 7\n",
    "death_err = np.sqrt(dow_sum['Deaths Squared'] / weeks / 7 - death_mean * death_mean) / np.sqrt(weeks)\n",
    "weekly_mean = weekly_sum / weeks / 7 / 7\n",
    "weekly_err = np.sqrt(weekly_sum_squared / weeks / 7 / 7 - weekly_mean * weekly_mean) / np.sqrt(weeks)\n",
    "kf_mean = (death_mean * (1 / death_err ** 2) + weekly_mean * (1 / weekly_err ** 2)\n",
    "                         ) / ((1 / death_err ** 2) + (1 / weekly_err ** 2))\n",
    "kf_err = np.sqrt(1 / ((1 / death_err ** 2) + (1 / weekly_err ** 2)))\n",
    "print(weekly_mean, weekly_err)\n",
    "print('Means of deaths', death_mean)\n",
    "print('Kalman filtered', (death_mean * (1 / death_err ** 2) + weekly_mean * (1 / weekly_err ** 2)\n",
    "                         ) / ((1 / death_err ** 2) + (1 / weekly_err ** 2)))\n",
    "\n",
    "plt.bar(DAYS_OF_THE_WEEK, death_mean, yerr=death_err, capsize=7)\n",
    "plt.title(AREA_OF_INTEREST[1] + ' detrended day-of-week deaths (' + str(weeks) + ' week average)')\n",
    "plt.show()\n",
    "\n",
    "plt.bar(DAYS_OF_THE_WEEK, kf_mean, yerr=kf_err, capsize=7)\n",
    "plt.title(AREA_OF_INTEREST[1] + ' kalman filtered day-of-week deaths (' + str(weeks) + ' week average)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is this statistically significant? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
